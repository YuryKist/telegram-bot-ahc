# import_1C.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–≥—Ä—É–∑–∫–∏ –∏–∑ 1–° –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –†–µ–µ—Å—Ç—Ä–∞ –ê–•–ß.
–û–∂–∏–¥–∞–µ—Ç:
- –§–∞–π–ª *–†–µ–µ—Å—Ç—Ä –ê–•–ß*.xlsx ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–µ—Å—Ç—Ä
- –§–∞–π–ª *–ü–ª–∞—Ç–µ–∂–Ω*.xlsx ‚Äî –≤—ã–ø–∏—Å–∫–∞ –∏–∑ 1–°
–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã –≤ —Ä–µ–µ—Å—Ç—Ä–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
"""

import pandas as pd
import re
from pathlib import Path
from loguru import logger
from openpyxl import load_workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.cell import MergedCell


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger.remove()
logger.add("1C_import.log", rotation="10 MB", level="INFO", encoding="utf-8")
logger.add(lambda msg: print(msg, end=''), level="INFO")



def load_ahx_data(directory_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–µ—Å—Ç—Ä –∏–∑ Excel (–Ω–∞—á–∏–Ω–∞—è —Å 4 —Å—Ç—Ä–æ–∫–∏)."""
    try:
        directory =  Path(directory_path)
        all_excel_files = list(directory.glob('*.xls*'))
        excel_files_AXCH = [
            f for f in all_excel_files 
            if '–∞—Ö—á' in f.name.lower()
            ]
        if not excel_files_AXCH:
            raise FileNotFoundError("‚ùå –§–∞–π–ª –≤—ã–ø–∏—Å–∫–∏ –∏–∑ –ê–•–ß –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        
        ahch_file_path = excel_files_AXCH[0]
        
        df_register = pd.read_excel(ahch_file_path, skiprows=3)
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_register)} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞.")
        return df_register, ahch_file_path
    
    except Exception as e:
        logger.error(f"[–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Excel] {e}")
        return None

def load_payment_data(directory_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—ã–ø–∏—Å–∫—É –∏–∑ 1–°."""
    try:
        directory = Path(directory_path)
        excel_files_payment = list(directory.glob('*–ü–ª–∞—Ç–µ–∂–Ω*.xls*'))

        if not excel_files_payment:
            raise FileNotFoundError("‚ùå –§–∞–π–ª –≤—ã–ø–∏—Å–∫–∏ –∏–∑ 1–° –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        df_export_1C = pd.read_excel(excel_files_payment[0], skiprows=4)
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_export_1C)} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞.")
        return df_export_1C
    
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤: {e}")
        return None


def extract_invoice_number(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (—Å—á—ë—Ç, –Ω–∞–∫–ª–∞–¥–Ω–∞—è –∏ —Ç.–¥.)."""
    if not isinstance(text, str):
        return None

    invoice_chars = r"[\w\-_+\/A-Za-z–ê-–Ø–∞-—è–Å—ë]"

    # 1. –ò—â–µ–º –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: "—Å—á–µ—Ç", "–Ω–∞–∫–ª–∞–¥–Ω–∞—è" –∏ —Ç.–¥.
    main_pattern = rf"""
        (?:—Å—á–µ—Ç[–∞—É]?|—Ñ–∞–∫—Ç—É—Ä[–µ–∞]|–Ω–∞–∫–ª–∞–¥–Ω[–æ–∏–π—è]|—Ç–æ–≤–∞—Ä–Ω[–∞—ã][–π—è]|—Ç–º—Ç|—Å\/?—Ñ|[—Åc]\/?—Ñ|—Ç–æ–≤\.?\s*–Ω–∞–∫–ª–∞–¥–Ω[–æ–∏–π—è])
        \b                      # –≥—Ä–∞–Ω–∏—Ü–∞ —Å–ª–æ–≤–∞
        \W*                     # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        ({invoice_chars}*?\d{invoice_chars}*)  # –Ω–æ–º–µ—Ä —Å —Ü–∏—Ñ—Ä–æ–π
    """
    match = re.search(main_pattern, text, re.IGNORECASE | re.DOTALL | re.VERBOSE)
    if match:
        return match.group(1).strip()

    # 2. –ò—â–µ–º –ø–æ—Å–ª–µ —Å–∏–º–≤–æ–ª–∞ ‚Ññ
    alt_match = re.search(r"‚Ññ\s*([A-Za-z–ê-–Ø–∞-—è–Å—ë\d\-_+\/]+)", text, re.IGNORECASE)
    if alt_match:
        return alt_match.group(1).strip()

    # 3. –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
    fallback_match = re.search(r"\b\d+\b", text)
    if fallback_match:
        return fallback_match.group(0).strip()

    logger.debug("–ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    return None

def prepare_register(df_register):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–µ–µ—Å—Ç—Ä: —É–±–∏—Ä–∞–µ—Ç –≤–µ–¥—É—â–∏–µ –Ω—É–ª–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç —Ç–∏–ø—ã."""
    logger.info("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–µ—Å—Ç –ê–•–ß")
    df_register = df_register.copy()
    df_register['‚Ññ —Å—á–µ—Ç–∞'] = df_register['‚Ññ —Å—á–µ—Ç–∞'].fillna('').astype("string")
    df_register['–°—É–º–º–∞'] = pd.to_numeric(df_register['–°—É–º–º–∞'], errors='coerce').round(2)
    df_register['‚Ññ –∑–∞–¥–∞—á–∏ –ë–∏—Ç—Ä–∏–∫—Å'] = pd.to_numeric(df_register['‚Ññ –∑–∞–¥–∞—á–∏ –ë–∏—Ç—Ä–∏–∫—Å'], errors='coerce').astype(dtype = int, errors = 'ignore')
    df_register['ID_–°—á–µ—Ç_Bitrix'] = pd.to_numeric(df_register['ID_–°—á–µ—Ç_Bitrix'], errors='coerce').astype(dtype = int, errors = 'ignore')

    logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.")
    return df_register


def prepare_export_1C(df_export_1C):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ: —É–±–∏—Ä–∞–µ—Ç –≤–µ–¥—É—â–∏–µ –Ω—É–ª–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç —Ç–∏–ø—ã."""
    
    logger.info("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–µ—Å—Ç—Ä–∞ 1C")
    df_export_1C = df_export_1C.copy()
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Å—á–µ—Ç–æ–≤ –∏–∑ "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"
    df_export_1C['–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞'] = df_export_1C['–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'].apply(extract_invoice_number)
    df_export_1C['–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞'] = df_export_1C['–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞'].astype(str).apply(
        lambda x: str(int(x)) if x.isdigit() else x
    )

    # –ü—Ä–∏–≤–æ–¥–∏–º —Å—É–º–º—ã –∫ —á–∏—Å–ª—É
    df_export_1C['–°—É–º–º–∞'] = pd.to_numeric(df_export_1C['–°—É–º–º–∞'], errors='coerce').round(2)

    logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.")
    return df_export_1C


def update_payment_status(df_export, df_register):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ ‚Ññ —Å—á—ë—Ç–∞ –∏ —Å—É–º–º–µ."""
    try:
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –≤—ã–ø–∏—Å–∫–µ
        df_export_unique = df_export.drop_duplicates(subset=['–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞', '–°—É–º–º–∞'])
        df_export_mapped = df_export_unique[['–ù–æ–º–µ—Ä —Å—á–µ—Ç–∞', '–°—É–º–º–∞', '–°–æ—Å—Ç–æ—è–Ω–∏–µ']].copy()
        df_export_mapped.columns = ['‚Ññ —Å—á–µ—Ç–∞', '–°—É–º–º–∞', '–°—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã']

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        df_merged = df_register.merge(
            df_export_mapped,
            on=['‚Ññ —Å—á–µ—Ç–∞', '–°—É–º–º–∞'],
            how='left',
            suffixes=('', '_–Ω–æ–≤—ã–π')
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—É—Å—Ç—ã–µ –∏–ª–∏ –Ω–µ–æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã
        mask = df_merged['–°—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã_–Ω–æ–≤—ã–π'].notna() & \
               (~df_register['–°—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã'].isin(["–û–ø–ª–∞—á–µ–Ω–æ", "–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ"]))
        df_register = df_register.copy()
        df_register.loc[mask, '–°—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã'] = df_merged.loc[mask, '–°—Ç–∞—Ç—É—Å –æ–ø–ª–∞—Ç—ã_–Ω–æ–≤—ã–π']

        updated_count = mask.sum()
        if updated_count > 0:
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count} —Å—Ç–∞—Ç—É—Å–æ–≤ –æ–ø–ª–∞—Ç—ã.")
        else:
            logger.info("‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

        return df_register
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞: {e}")
        return df_register


def update_date_payment(df_register):
    # –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–Ω–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
    days_dict = {
        '–∏–ø —à–∞–π–¥—É–ª–∏–Ω': 30,
        '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è 21–≤–µ–∫': 0,
        '–∫–æ—Ä–µ–∫—Å–º–∞—Ä–∫–µ—Ç': 28,
        '—Ä–µ–≥–∏–æ–Ω-—Å–Ω–∞–±–∂–µ–Ω–∏–µ': 28,
        '–∫—É—Ä—ã—à–µ–≤': 25,
        '—É–ø–∞–∫–æ–≤–æ—á–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã': 30,
        '–∏–ø –ø–∞–≤–ª–æ–≤ –µ.–≤.': 0
    }
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    df_result = df_register.copy()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    updated_count = 0
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É '–î–∞—Ç–∞ —Å—á–µ—Ç–∞' –≤ datetime —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∞
        df_result['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'] = pd.to_datetime(df_result['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'], errors='coerce', format='%d.%m.%Y', dayfirst=True)
        
        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –æ—á–∏—â–∞–µ–º –∫–æ–ª–æ–Ω–∫—É '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã' –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã' not in df_result.columns:
            df_result['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'] = None
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞
        for index, row in df_result.iterrows():
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞—Ç–∞ —Å—á–µ—Ç–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                if pd.notna(row['–î–∞—Ç–∞ —Å—á–µ—Ç–∞']):
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
                    supplier = str(row['–ü–æ—Å—Ç–∞–≤—â–∏–∫']).lower().strip()
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                    days_to_add = days_dict.get(supplier, 0)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–Ω–∏ –∫ –¥–∞—Ç–µ —Å—á–µ—Ç–∞
                    new_date = row['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'] + pd.Timedelta(days=days_to_add)
                    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∫–æ–ª–æ–Ω–∫—É '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'
                    df_result.at[index, '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'] = new_date
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                    updated_count += 1
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏ {index}: {e}")
                continue
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã' –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
        if '–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã' in df_result.columns and not df_result['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'].empty:
            df_result['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'] = pd.to_datetime(df_result['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'], errors='coerce').dt.strftime('%d.%m.%Y')
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count} –¥–∞—Ç –∫–æ–Ω—Ç—Ä–æ–ª—è –æ–ø–ª–∞—Ç—ã.")
        
    except Exception as e:
        logger.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞—Ç: {e}")
        logger.error(f"–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ '–î–∞—Ç–∞ —Å—á–µ—Ç–∞': {df_result['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'].dtype if '–î–∞—Ç–∞ —Å—á–µ—Ç–∞' in df_result.columns else '–ö–æ–ª–æ–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    
    return df_result


def update_excel_file(file_path, df):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ Excel —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    try:
        df_save = df.copy()

        # –ø—Ä–∏–≤–æ–¥–∏–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç –∫ EXCEL
        date_columns = ['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã', '–î–∞—Ç–∞ —Å—á–µ—Ç–∞']
        for col in date_columns:
            if col in df_save.columns:
                if pd.api.types.is_datetime64_any_dtype(df_save[col]):
                    df_save[col] = df_save[col].dt.strftime('%d.%m.%Y')
                elif df_save[col].dtype == 'object':
                    try:
                        parsed = pd.to_datetime(
                            df_save[col], 
                            errors='coerce',
                            dayfirst=True,
                            format='%d.%m.%Y'
                        )
                        if parsed.notna().any():
                            df_save[col] = parsed.dt.strftime('%d.%m.%Y').where(parsed.notna(), df_save[col])
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–ª–æ–Ω–∫–∏ '{col}': {e}")
                        pass

        wb = load_workbook(file_path)
        ws = wb.active

        for row in ws.iter_rows(min_row=4):
            for cell in row:
                if not isinstance(cell, MergedCell):
                    cell.value = None

        for col_idx, col_name in enumerate(df_save.columns, 1):
            ws.cell(row=4, column=col_idx, value=col_name)

        for row_idx, row in enumerate(dataframe_to_rows(df_save, index=False, header=False), 5):
            for col_idx, value in enumerate(row, 1):
                ws.cell(row=row_idx, column=col_idx, value=value)

        wb.save(file_path)
        logger.info(f"üíæ –†–µ–µ—Å—Ç—Ä –æ–±–Ω–æ–≤–ª—ë–Ω: {file_path}")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ Excel: {e}")
        return False


def run_pipeline(directory_path: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—ã–ø–∏—Å–∫–∏ –∏–∑ 1–° –≤ —Ä–µ–µ—Å—Ç—Ä.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è Telegram-–±–æ—Ç–∞.
    """
    try:
        logger.info("üîπ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–ø–∏—Å–∫–∏ –∏–∑ 1–°")

        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
        df_register, ahch_path = load_ahx_data(directory_path)
        df_export_1C = load_payment_data(directory_path)

        # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df_export_clean = prepare_export_1C(df_export_1C)
        df_register_clean = prepare_register(df_register)

        # –®–∞–≥ 3: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        df_register_updadate = update_payment_status(df_export_clean, df_register_clean)
        df_register_updadate = update_date_payment(df_register_updadate)

        # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        success = update_excel_file(ahch_path, df_register_updadate)
        if success:
            return "‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑ 1–° –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ –†–µ–µ—Å—Ç—Ä–µ –ê–•–ß."
        else:
            return "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞."

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"


# --- –î–ª—è —Ç–µ—Å—Ç–∞ ---
if __name__ == "__main__":
    test_path = r"C:\Users\–Æ—Ä–∏–π –ö–∏—Å—Ç–µ–Ω–µ–≤\Desktop\ACH_manager\record"
    result = run_pipeline(test_path)
    print(result)