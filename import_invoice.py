# import_invoice.py
"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF-—Å—á–µ—Ç–æ–≤ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –†–µ–µ—Å—Ç—Ä–∞ –ê–•–ß.
–û–∂–∏–¥–∞–µ—Ç:
- PDF-—Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—Å —Ñ—Ä–∞–∑–æ–π "—Å—á–µ—Ç")
- –§–∞–π–ª *–†–µ–µ—Å—Ç—Ä –ê–•–ß*.xlsx ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–µ—Å—Ç—Ä
–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Å—á–µ—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ.
"""

import re
import pdfplumber
import pandas as pd
from datetime import datetime
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from dateutil.parser import parse
from loguru import logger
from import_1C import update_excel_file as update_excel_file
from import_1C import load_ahx_data as load_ahx_data
from import_1C import prepare_register as prepare_register

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ —Ñ–∞–π–ª –∏ –≤ stdout)
logger.remove()  # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π handler
logger.add("invoice_log.log", rotation="10 MB", level="INFO", encoding="utf-8", backtrace=True, diagnose=True)
logger.add(lambda msg: print(msg, end=''), level="INFO", colorize=True)  # –õ–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª—å


def get_pdf_files(directory):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ PDF-—Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    try:
        dir_path = Path(directory)
        if not dir_path.is_dir():
            raise NotADirectoryError(f"–ü—É—Ç—å '{directory}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π.")
        pdf_files = [f.name for f in dir_path.iterdir() if f.is_file() and f.suffix.lower() == '.pdf']
        logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF-—Ñ–∞–π–ª–æ–≤.")
        return pdf_files
    except Exception as e:
        logger.error(f"[–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ PDF] {e}")
        return []


def process_pdf_files(directory, filename):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –æ–¥–Ω–æ–≥–æ PDF-—Ñ–∞–π–ª–∞."""
    file_path = Path(directory) / filename
    try:
        with pdfplumber.open(file_path) as pdf:
            text = ''
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            logger.info(f"üìÑ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á—ë–Ω —Ç–µ–∫—Å—Ç –∏–∑ '{filename}' ({len(text)} —Å—Ç—Ä.)")
            logger.info(f"{text[100:300]}")
            return text
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF '{filename}': {e}")
        return None


def extract_amount(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É–º–º—É –ø–æ—Å–ª–µ —Ñ—Ä–∞–∑—ã '–Ω–∞ —Å—É–º–º—É'."""
    match = re.search(r'(?:–Ω–∞ —Å—É–º–º—É)\D*([0-9\s.,]+)', text, re.IGNORECASE | re.DOTALL)
    if match:
        amount_str = match.group(1).strip()
        cleaned = re.sub(r'[^\d.,]', '', amount_str).replace(',', '.')
        amount = pd.to_numeric(cleaned, errors='coerce')
        if pd.notna(amount):
            logger.info(f"üí∞ –ò–∑–≤–ª–µ—á–µ–Ω–∞ —Å—É–º–º–∞: {amount}")
            return amount
    logger.debug("–°—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return None


def extract_supplier(text: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ (–û–û–û –∏–ª–∏ –ò–ü)."""
    lower_text = text.lower()
    match_start = re.search(r'–ø–æ–ª—É—á–∞—Ç–µ–ª', lower_text)
    if not match_start:
        logger.debug("–ü–æ—Å—Ç–∞–≤—â–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None 
    
    # –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ
    search_area = text[match_start.start():]
    logger.debug(f"üîç Search area: {repr(search_area[:100])}")
    patterns = [
        # 3. –ò–ü –ø–æ–ª–Ω–æ–µ –∏–º—è (–±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –ø–æ—Å–ª–µ –ò–ü)
        r'–ò–ü\s+([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\-]+)',
        # 4. –ò–ü —Å –∏–Ω–∏—Ü–∏–∞–ª–∞–º–∏
        r'–ò–ü\s+([–ê-–Ø–Å][–∞-—è—ë]+?)\s+[–ê-–Ø–Å]\.\s*[–ê-–Ø–Å]\.',
        # 5. –ü–æ–ª–Ω–∞—è —Ñ–æ—Ä–º–∞ –ò–ü
        r'–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π\s+–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å\s+([–ê-–Ø–Å][–∞-—è—ë]+)',
        # 1. –û–û–û –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–ª—é–±—ã–µ –∫–∞–≤—ã—á–∫–∏: ¬´¬ª, "", '')
        r'–û–û–û\s*[¬´"]([^¬ª"]+?)[¬ª"]',
        # 2. –û–û–û –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ ‚Äî –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—Å—ë –¥–æ –ø–µ—Ä–≤–æ–≥–æ "—Å—Ç–æ–ø-—Å–ª–æ–≤–∞" –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏
        r'–û–û–û\s+([–ê-–Ø–Å][–ê-–Ø–Å–∞-—è—ë\s\-]+?)(?=\s+(?:–ò–ù–ù|–ö–ü–ü|–°—á\.?|–í–∏–¥|–ù–∞–∑\.|–û—á–µ—Ä|–ö–æ–¥|–†–µ–∑|–û–ø–ª–∞—Ç–∞|–ë–∞–Ω–∫|$))'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, search_area)
        if match:
            name = match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            name = re.sub(r'^["¬´"]+|["¬ª"]+$', '', name)
            supplier = name.strip()
            logger.info(f"üè≠ –ü–æ—Å—Ç–∞–≤—â–∏–∫: {supplier}")
            return supplier
    
    logger.debug("–ü–æ—Å—Ç–∞–≤—â–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    return None  # –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ


def get_date_from_line(text: str):
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Å—è—Ü–µ–≤ –≤ —á–∏—Å–ª–∞
    month_names = {
        '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
        '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
        '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
    }

    # 1. –ü–æ–∏—Å–∫ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–¥.–º–º.–≥–≥–≥–≥
    dot_date_match = re.search(r'(\d{1,2})\.(\d{1,2})\.(\d{4})', text)
    if dot_date_match:
        day, month, year = map(int, dot_date_match.groups())
        try:
            date_part = datetime(year, month, day).date()
            logger.info(f"üìÜ –ò–∑–≤–ª–µ—á–µ–Ω–∞ –¥–∞—Ç–∞: {date_part}")
            return date_part
        except ValueError:
            pass  # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–∞—Ç–∞

    # 2. –ü–æ–∏—Å–∫ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–¥ (–∏–ª–∏ –¥–¥) –º–µ—Å—è—Ü –≥–≥–≥–≥"
    word_date_pattern = r'(\d{1,2})\s*([–∞-—è—ë]+)\s+(\d{4})\s*(?:–≥\.?)?'
    matches = re.finditer(word_date_pattern, text, re.IGNORECASE)
    for match in matches:
        day_str, month_word, year_str = match.groups()
        day = int(day_str)
        year = int(year_str)
        month_word = month_word.lower()

        if month_word in month_names:
            month = month_names[month_word]
            try:
                date_part = datetime(year, month, day).date()
                logger.info(f"üìÜ –ò–∑–≤–ª–µ—á–µ–Ω–∞ –¥–∞—Ç–∞: {date_part}")
                return date_part
            except ValueError:
                continue  # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–∞—Ç–∞

    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    return None


def get_num_invoce(text, target_phrase):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –ø–æ –∫–ª—é—á–µ–≤–æ–π —Ñ—Ä–∞–∑–µ."""
    invoice_number = None
    for line in text.splitlines():
        if target_phrase in line.lower():
            parts = line.split("–æ–ø–ª–∞—Ç—É ‚Ññ")
            if len(parts) > 1:
                invoice_number = parts[1].strip().split()[0]
                break
    logger.info(f"üí∞ –ò–∑–≤–ª–µ—á–µ–Ω –Ω–æ–º–µ—Ä: {invoice_number}")
    return invoice_number


def extract_invoice_data(pdf_files, directory, target_phrase="—Å—á–µ—Ç"):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö PDF-—Ñ–∞–π–ª–æ–≤."""
    invoice_data_list = []
    for f in pdf_files:
        try:
            text = process_pdf_files(directory, f)
            if not text:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ '{f}'. –ü—Ä–æ–ø—É—â–µ–Ω.")
                continue

            invoice_number = get_num_invoce(text, target_phrase)
            invoice_date = get_date_from_line(text)
            supplier = extract_supplier(text)
            amount = extract_amount(text)
            invoice_data_list.append({
                    '‚Ññ —Å—á–µ—Ç–∞': invoice_number,
                    '–î–∞—Ç–∞ —Å—á–µ—Ç–∞': invoice_date,
                    '–ü–æ—Å—Ç–∞–≤—â–∏–∫': supplier,
                    '–°—É–º–º–∞': amount
                })

            logger.info(f"‚úÖ –°—á—ë—Ç ‚Ññ{invoice_number} –¥–æ–±–∞–≤–ª–µ–Ω –∏–∑ '{f}'")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{f}': {e}")

    
    invoice_df = pd.DataFrame(invoice_data_list, columns=['‚Ññ —Å—á–µ—Ç–∞', '–î–∞—Ç–∞ —Å—á–µ—Ç–∞', '–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–°—É–º–º–∞'])
    invoice_df['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'] = pd.to_datetime(invoice_df['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'], errors='coerce')
    invoice_df['–ö–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–ª–∞—Ç—ã'] = invoice_df['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'] + pd.Timedelta(days=21)
    invoice_df['‚Ññ —Å—á–µ—Ç–∞'] = invoice_df['‚Ññ —Å—á–µ—Ç–∞'].pipe(
        lambda series: series.fillna('')
        .astype("string")
        .str.lower()
        .str.lstrip('0')
    )

    invoice_df['–°—É–º–º–∞'] = pd.to_numeric(invoice_df['–°—É–º–º–∞'], errors='coerce').round(2)

    return invoice_df


def update_register_with_new_invoices(df_register, df_invoice_reg):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Ä–µ–µ—Å—Ç—Ä —Å—á–µ—Ç–æ–≤, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ —Å—á–µ—Ç–∞ –∏–∑ df_invoice_reg.
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π.
    """
    if df_invoice_reg.empty:
        logger.info("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—á–µ—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä.")
        return "‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—á–µ—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä."
    try:
        # 1. –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –Ω–æ–≤—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
        df_export_unique = df_invoice_reg.drop_duplicates(subset=['‚Ññ —Å—á–µ—Ç–∞', '–°—É–º–º–∞'])
        df_register_keep = df_register[['‚Ññ —Å—á–µ—Ç–∞', '–°—É–º–º–∞']]
        
        df_merged = df_export_unique.merge(
            df_register_keep,
            on=['‚Ññ —Å—á–µ—Ç–∞', '–°—É–º–º–∞'],
            how='left',
#            suffixes=('', '_merge'),
            indicator=True
            )
        new_rows = df_merged[df_merged['_merge'] == 'left_only'].drop('_merge', axis=1)
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {new_rows} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ —Ä–µ–µ—Å—Ç—Ä.")
        df_register = pd.concat([df_register, new_rows], ignore_index=True)

        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_rows)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –≤ —Ä–µ–µ—Å—Ç—Ä.")
        # 2. –ü—Ä–∏–≤–æ–¥–∏–º –¥–∞—Ç—ã –∫ —Ñ–æ—Ä–º–∞—Ç—É datetime
#        df_register['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'] = pd.to_datetime(df_register['–î–∞—Ç–∞ —Å—á–µ—Ç–∞'], errors='coerce')
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –Ω–æ–º–µ—Ä–æ–≤ "–Æ-..."
        df_register['number_part'] = df_register['‚Ññ —Å–∏–Ω–µ–π –Ω–∞–∫–ª–∞–¥–Ω–æ–π'].str.extract(r'(\d+)')[0]
        df_register['number_part'] = pd.to_numeric(df_register['number_part'], errors='coerce')
        # 4. –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä
        last_number = df_register['number_part'].max()
        start_num = int(last_number) + 1 if pd.notna(last_number) else 1
        # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –Ω–æ–º–µ—Ä–∞ –¥–ª—è NaN
        nan_count = df_register['‚Ññ —Å–∏–Ω–µ–π –Ω–∞–∫–ª–∞–¥–Ω–æ–π'].isna().sum()
        last_prefix = df_register['‚Ññ —Å–∏–Ω–µ–π –Ω–∞–∫–ª–∞–¥–Ω–æ–π'].str.findall(r'[–ê-–Ø–Å]+').str[-1].loc[0]
        new_numbers = [f'{last_prefix}-{i}' for i in range(start_num, start_num + nan_count)]
        # 6. –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        df_register.loc[df_register['‚Ññ —Å–∏–Ω–µ–π –Ω–∞–∫–ª–∞–¥–Ω–æ–π'].isna(), '‚Ññ —Å–∏–Ω–µ–π –Ω–∞–∫–ª–∞–¥–Ω–æ–π'] = new_numbers
        # 7. –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü
        df_register.drop(columns=['number_part'], inplace=True)
        return df_register
    except Exception as e:
        logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ä–µ–µ—Å—Ç—Ä–∞: {e}")
        return "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ä–µ–µ—Å—Ç—Ä–∞"

def run_pipeline(directory_path: str) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞–π–ø–ª–∞–π–Ω.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É-—Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è Telegram-–±–æ—Ç–∞.
    """
    try:
        logger.info("üîπ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞: –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF-—Å—á–µ—Ç–æ–≤")

        # –®–∞–≥ 1: –ü–æ–∏—Å–∫ PDF
        pdf_files = get_pdf_files(directory_path)
        if not pdf_files:
            return "‚ö†Ô∏è –í –ø–∞–ø–∫–µ –Ω–µ—Ç PDF-—Ñ–∞–π–ª–æ–≤."

        # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–µ—Å—Ç—Ä–∞
        df_register, output_file_path = load_ahx_data(directory_path)
        df_register_clean = prepare_register(df_register)

        logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–µ—Å—Ç—Ä–∞: {output_file_path}")

        # –®–∞–≥ 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PDF
        df_invoice_reg = extract_invoice_data(pdf_files, directory_path, "—Å—á–µ—Ç")
        if df_invoice_reg.empty:
            return "‚ÑπÔ∏è –ù–æ–≤—ã—Ö —Å—á–µ—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

        # –®–∞–≥ 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–µ—Å—Ç—Ä–∞
        df_updated = update_register_with_new_invoices(df_register_clean, df_invoice_reg)

        # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        success = update_excel_file(output_file_path, df_updated)
        if success:
            logger.success("–î–∞–Ω–Ω—ã–µ –∏–∑ Bitrix —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ –†–µ–µ—Å—Ç—Ä–µ –ê–•–ß")
            return "‚úÖ –°—á–µ—Ç–∞ –∏–∑ PDF –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –†–µ–µ—Å—Ç—Ä –ê–•–ß."
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {success}")
            return "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞."

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"


# --- –î–ª—è —Ç–µ—Å—Ç–∞ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) ---
if __name__ == "__main__":
    test_path = r"C:\Users\–Æ—Ä–∏–π –ö–∏—Å—Ç–µ–Ω–µ–≤\Desktop\ACH_manager\record"
    result = run_pipeline(test_path)
    print(result)